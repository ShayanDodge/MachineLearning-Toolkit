{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `The Data API`\n",
    "In TensorFlow, the Data API refers to a set of tools and utilities provided by TensorFlow for efficiently loading and preprocessing data. It offers a streamlined and flexible way to work with large datasets, making it easier to build and train machine learning models.\n",
    "\n",
    "* The Data API in TensorFlow centers on the notion of a **dataset**, which is essentially a sequence of data items. While datasets typically read data from disk incrementally, for simplicity, one can create a dataset entirely in RAM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creating Dataset\n",
    "* The `from_tensor_slices()` function in TensorFlow takes a tensor and generates a `tf.data.Dataset` where each element corresponds to a slice of the input tensor along its first dimension. For example, if the input tensor has a shape of (10, ...), the resulting dataset will contain 10 items, each representing a slice of the tensor along the first dimension, namely tensors 0 through 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n",
      "tf.Tensor(6, shape=(), dtype=int64)\n",
      "tf.Tensor(7, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(9, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Generate a tensor containing values from 0 to 9 using tf.range()\n",
    "X = tf.range(10)\n",
    "\n",
    "# Create a tf.data.Dataset from the tensor X using from_tensor_slices()\n",
    "# This function creates a dataset where each element is a slice of X along its first dimension\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
    "\n",
    "# Print the dataset to observe its structure\n",
    "print(dataset)\n",
    "\n",
    "# Alternatively, you can create a dataset containing a range of values from 0 to 9 using tf.data.Dataset.range()\n",
    "dataset = tf.data.Dataset.range(10)\n",
    "\n",
    "# Iterate through the dataset and print each item\n",
    "for item in dataset:\n",
    "    print(item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chaining Transformations\n",
    "\n",
    "In the context of TensorFlow's Data API, transformations refer to the operations applied to datasets to **modify** or **preprocess** the data in various ways. These transformations are used to prepare the data for training machine learning models.\n",
    "\n",
    "**Common transformations include:**\n",
    "\n",
    "* **Batching**: Grouping multiple examples into batches, which enables processing multiple examples in parallel, typically to improve efficiency during training.\n",
    "\n",
    "* **Repeating**: The `repeat()` transformation is used to repeat the elements of a dataset for a specified number of epochs or indefinitely if no argument is provided. This transformation is often used to ensure that the dataset provides enough data for training over multiple epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int64)\n",
      "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int64)\n",
      "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int64)\n",
      "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int64)\n",
      "tf.Tensor([8 9], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# Repeat the dataset third time to create a new dataset that contains two repetitions of the original data\n",
    "# Then, batch the dataset into batches of size 7, meaning each batch will contain 7 elements\n",
    "dataset = dataset.repeat(3).batch(7)\n",
    "\n",
    "# Iterate through the transformed dataset\n",
    "for item in dataset:\n",
    "    # Print each batch of the dataset\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int64)\n",
      "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int64)\n",
      "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int64)\n",
      "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create a dataset containing elements from 0 to 9\n",
    "dataset = tf.data.Dataset.range(10)\n",
    "\n",
    "# Repeat the dataset twice\n",
    "dataset = dataset.repeat(3)\n",
    "\n",
    "# Batch the dataset into batches of size 7, dropping any remainder\n",
    "dataset = dataset.batch(7, drop_remainder=True)\n",
    "\n",
    "# Iterate through the dataset\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Mapping**: Applying a function to each element of the dataset. This function can be used for various purposes, such as data preprocessing, feature engineering, or data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "4\n",
      "9\n",
      "16\n",
      "25\n",
      "36\n",
      "49\n",
      "64\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define a simple transformation function\n",
    "def square(x):\n",
    "    return x ** 2\n",
    "\n",
    "# Create a dataset containing elements from 0 to 9\n",
    "dataset = tf.data.Dataset.range(10)\n",
    "\n",
    "# Apply the square function to each element of the dataset in parallel\n",
    "# Specify num_parallel_calls to control the degree of parallelism\n",
    "# Here, tf.data.experimental.AUTOTUNE dynamically determines the degree of parallelism\n",
    "dataset = dataset.map(square, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Iterate through the transformed dataset\n",
    "for item in dataset:\n",
    "    print(item.numpy())  # Print each transformed element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Applying**: The `apply()` method is used to apply a transformation that operates on the dataset as **a whole** rather than individual elements.\n",
    "\n",
    "   * It allows for more complex transformations that involve **aggregating**, **filtering**, or **modifying** the dataset **as a whole**.\n",
    "\n",
    "   * The `apply()` method can be used to perform operations such as **batch-wise normalization**, or custom dataset preprocessing.\n",
    "\n",
    "   * Unlike the `map()` method, the transformation function passed to `apply()` operates on the entire dataset or subsets of it rather than individual elements. \n",
    "\n",
    "   * The transformation function passed to the apply() method must return a new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create a dataset containing elements from 0 to 4\n",
    "dataset = tf.data.Dataset.range(5)\n",
    "\n",
    "# Define a transformation function to create a copy of the dataset\n",
    "def copy_dataset(ds):\n",
    "    return ds\n",
    "\n",
    "# Apply the copy_dataset function to the dataset using the apply() method\n",
    "copied_dataset = dataset.apply(copy_dataset)\n",
    "\n",
    "# Iterate through the copied dataset\n",
    "for item in copied_dataset:\n",
    "    print(item.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Filtering**: Removing examples from the dataset based on certain criteria, such as removing outliers or selecting specific classes for classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create a dataset containing elements from 0 to 9\n",
    "dataset = tf.data.Dataset.range(10)\n",
    "\n",
    "# Apply a filter using a lambda function to keep only elements greater than 5\n",
    "filtered_dataset = dataset.filter(lambda x: x > 5)\n",
    "\n",
    "# Iterate through the filtered dataset\n",
    "for item in filtered_dataset:\n",
    "    print(item.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shuffling**: Randomly shuffling the data to introduce randomness and prevent the model from learning the order of the examples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
