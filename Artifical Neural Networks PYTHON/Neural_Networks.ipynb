{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* # Perceptron neural network\n",
    "\n",
    "    * A perceptron is the simplest form of a neural network, specifically a single-layer neural network. \n",
    "    * It was introduced by Frank Rosenblatt in 1957. \n",
    "    * The perceptron is a binary classifier that takes multiple binary inputs and produces a single binary output.  \n",
    "    * It's a fundamental building block for more complex neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "# Extract petal length and petal width features from the dataset\n",
    "X = iris.data[:, (2, 3)]  # petal length, petal width\n",
    "# Create binary classification labels: 1 if Iris setosa, 0 otherwise\n",
    "y = (iris.target == 0).astype(int)\n",
    "\n",
    "# Create a Perceptron classifier with specified parameters\n",
    "## max_iter is the maximum number of training iterations.\n",
    "## tol is the tolerance, stopping training when the improvement is small.\n",
    "## random_state ensures reproducibility by setting a random seed.\n",
    "per_clf = Perceptron(max_iter=1000, tol=1e-3, random_state=42)\n",
    "# Train the Perceptron on the dataset\n",
    "per_clf.fit(X, y)\n",
    "# Make a prediction for a new input [2, 0.5]\n",
    "y_pred = per_clf.predict([[2, 0.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* # Building an image classifire using TensorFlow and Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version is  2.10.0\n",
      "Keras version is  2.10.0\n",
      "The training set contains 60000 grayscale images, each 28*28 pixels\n",
      "The first image in the training set is a Coat\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_17 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, let's import TensorFlow and Keras.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Print TensorFlow and Keras versions.\n",
    "print('TensorFlow version is ', tf.__version__)\n",
    "print('Keras version is ', keras.__version__)\n",
    "\n",
    "# Loading the fashion MNIST dataset.\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Get the shape of the training set.\n",
    "(m, n1, n2) = X_train_full.shape\n",
    "print(f\"The training set contains {m} grayscale images, each {n1}*{n2} pixels\")\n",
    "\n",
    "# Split the training set into validation and training sets, and normalize pixel values.\n",
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n",
    "# Normalize pixel values in the test set.\n",
    "X_test = X_test / 255.\n",
    "\n",
    "# # plot an image using Matplotlib's `imshow()` function, with a 'binary' color map\n",
    "# plt.imshow(X_train[0], cmap=\"binary\")\n",
    "# plt.axis('off')\n",
    "# plt.show()\n",
    "\n",
    "# Defining the corresponding class names\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "# Printing the class name of the first image in the training set\n",
    "print(f\"The first image in the training set is a {class_names[y_train[0]]}\")\n",
    "\n",
    "# Creating a Sequential model\n",
    "model = keras.models.Sequential()\n",
    "# Adding a Flatten layer to reshape the input images into a 1D array\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "# Adding a Dense layer with 300 neurons and ReLU activation function\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "# Adding another Dense layer with 100 neurons and ReLU activation function\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "# Adding the output layer with 10 neurons (for each class) and softmax activation function\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# # Instead of adding the layers one by one as we just did, you can pass a list\n",
    "# # of layers when creating the Sequential model\n",
    "# model = keras.models.Sequential([\n",
    "#     keras.layers.Flatten(input_shape=[28, 28]),\n",
    "#     keras.layers.Dense(300, activation=\"relu\"),\n",
    "#     keras.layers.Dense(100, activation=\"relu\"),\n",
    "#     keras.layers.Dense(10, activation=\"softmax\")\n",
    "# ])\n",
    "\n",
    "# Displaying a summary of the model architecture, including parameters and output shapes\n",
    "model.summary()\n",
    "\n",
    "# Plotting the model architecture and saving it as an image\n",
    "# keras.utils.plot_model(model, \"my_fashion_mnist_model.png\", show_shapes=True)\n",
    "\n",
    "# Accessing information about the layers in the model\n",
    "model.layers\n",
    "hidden1 = model.layers[1]# Retrieving information about the first hidden layer\n",
    "hidden1.name# Retrieving the name of the first hidden layer\n",
    "\n",
    "# Retrieving the weights and biases from the first hidden layer\n",
    "weights, biases = hidden1.get_weights()\n",
    "weights.shape# Displaying the shape of the weights\n",
    "biases.shape# Displaying the shape of the biases\n",
    "\n",
    "# Compiling the model with sparse categorical crossentropy loss,\n",
    "# stochastic gradient descent (sgd) optimizer, and accuracy metric\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Training the model on the training data (X_train, y_train) for 30 epochs,\n",
    "# with validation data provided (X_valid, y_valid)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
