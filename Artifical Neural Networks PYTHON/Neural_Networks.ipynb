{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* # Perceptron neural network\n",
    "\n",
    "    * A perceptron is the simplest form of a neural network, specifically a single-layer neural network. \n",
    "    * It was introduced by Frank Rosenblatt in 1957. \n",
    "    * The perceptron is a binary classifier that takes multiple binary inputs and produces a single binary output.  \n",
    "    * It's a fundamental building block for more complex neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "# Extract petal length and petal width features from the dataset\n",
    "X = iris.data[:, (2, 3)]  # petal length, petal width\n",
    "# Create binary classification labels: 1 if Iris setosa, 0 otherwise\n",
    "y = (iris.target == 0).astype(int)\n",
    "\n",
    "# Create a Perceptron classifier with specified parameters\n",
    "## max_iter is the maximum number of training iterations.\n",
    "## tol is the tolerance, stopping training when the improvement is small.\n",
    "## random_state ensures reproducibility by setting a random seed.\n",
    "per_clf = Perceptron(max_iter=1000, tol=1e-3, random_state=42)\n",
    "# Train the Perceptron on the dataset\n",
    "per_clf.fit(X, y)\n",
    "# Make a prediction for a new input [2, 0.5]\n",
    "y_pred = per_clf.predict([[2, 0.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* # Building an image classifire using TensorFlow and Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version is  2.10.0\n",
      "Keras version is  2.10.0\n",
      "the training set contains 60000 grayscale images, each 28*28 pixels\n"
     ]
    }
   ],
   "source": [
    "# First, let's import TensorFlow and Keras.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Print TensorFlow and Keras versions.\n",
    "print('TensorFlow version is ', tf.__version__)\n",
    "print('Keras version is ', keras.__version__)\n",
    "\n",
    "# Loading the fashion MNIST dataset.\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Get the shape of the training set.\n",
    "(m, n1, n2) = X_train_full.shape\n",
    "print(f\"The training set contains {m} grayscale images, each {n1}*{n2} pixels\")\n",
    "\n",
    "# Split the training set into validation and training sets, and normalize pixel values.\n",
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n",
    "# Normalize pixel values in the test set.\n",
    "X_test = X_test / 255.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
