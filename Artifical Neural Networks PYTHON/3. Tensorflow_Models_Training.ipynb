{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Using TensorFlow like NumPy`\n",
    "* TensorFlow can be used in a way similar to NumPy for numerical computations, array manipulations, and mathematical operations. \n",
    "* TensorFlow like NumPy allows you to benefit from TensorFlow's powerful features such as `automatic differentiation`, `GPU acceleration`, `distributed computing`, and seamless integration with `deep learning frameworks`. This approach is ideal for scientific computing and building complex machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors and operations\n",
    "\n",
    "* In TensorFlow, `tensors` are fundamental objects that represent data in the computation graph. They flow through operations, allowing for efficient computation and differentiation.\n",
    "\n",
    "* Tensors are central to TensorFlow's design, enabling efficient and scalable computation in deep learning models. By understanding how to create and manipulate tensors, you can effectively work with TensorFlow's API to build and train sophisticated machine learning models.\n",
    "\n",
    "* These tensors will be important when we create `custom cost functions`, `custom metrics`, `custom layers`, and more, so letâ€™s see how to create and manipulate them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Creating Tensors\n",
    "* You can create tensors in TensorFlow just like NumPy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "<dtype: 'int32'>\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create a constant tensor (Immutable:)\n",
    "a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "\n",
    "# Create a variable tensor (can be updated)\n",
    "b = tf.Variable([[1.0, 2.0], [3.0, 4.0]])\n",
    "\n",
    "# Accessing shape, dtype, and ndim\n",
    "tensor = tf.constant([[1, 2], [3, 4]])\n",
    "# shape: Attribute that returns the shape of the tensor.\n",
    "print(tensor.shape)  # Output: (2, 2)\n",
    "# dtype: Attribute that returns the data type of the tensor.\n",
    "print(tensor.dtype)  # Output: <dtype: 'int32'>\n",
    "# ndim: Method that returns the number of dimensions (or rank) of the tensor.\n",
    "print(tensor.ndim)  # Output: 2\n",
    "\n",
    "# Create tensors with specified shape and dtype\n",
    "zeros_tensor = tf.zeros((3, 3), dtype=tf.float32)\n",
    "ones_tensor = tf.ones((2, 2), dtype=tf.int32)\n",
    "random_tensor = tf.random.normal((3, 3), mean=0.0, stddev=1.0, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Indexing\n",
    "* Indexing refers to accessing individual elements within a tensor using specific indices :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define a 2D tensor\n",
    "tensor_2d = tf.constant([[1, 2, 3],\n",
    "                          [4, 5, 6]])\n",
    "\n",
    "# Accessing individual elements\n",
    "print(tensor_2d[0, 0])  # Output: 1\n",
    "print(tensor_2d[1, 2])  # Output: 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Slicing\n",
    "* Slicing allows you to extract sub-tensors (slices) from a larger tensor based on specific ranges of indices along each dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
      "tf.Tensor([2 5], shape=(2,), dtype=int32)\n",
      "tf.Tensor([[4 5]], shape=(1, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Slicing along rows and columns\n",
    "print(tensor_2d[0, :])  # Slice the first row: [1, 2, 3]\n",
    "print(tensor_2d[:, 1])  # Slice the second column: [2, 5, 8]\n",
    "\n",
    "# Slicing sub-tensors\n",
    "print(tensor_2d[1:, :2])  # Slice rows from index 1 onwards and columns up to index 2:\n",
    "                          # [[4, 5],\n",
    "                          #  [7, 8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[10 11 12]\n",
      " [13 14 15]\n",
      " [16 17 18]], shape=(3, 3), dtype=int32)\n",
      "tf.Tensor([ 5 14 23], shape=(3,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 1  4  7]\n",
      " [10 13 16]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define a 3D tensor (3x3x3)\n",
    "tensor_3d = tf.Variable([\n",
    "    [[1, 2, 3],\n",
    "     [4, 5, 6],\n",
    "     [7, 8, 9]],\n",
    "\n",
    "    [[10, 11, 12],\n",
    "     [13, 14, 15],\n",
    "     [16, 17, 18]],\n",
    "\n",
    "    [[19, 20, 21],\n",
    "     [22, 23, 24],\n",
    "     [25, 26, 27]]\n",
    "])\n",
    "\n",
    "# Slicing along different dimensions\n",
    "print(tensor_3d[1, :, :])  # Slice the entire 2nd 'layer' (2nd matrix)\n",
    "print(tensor_3d[:, 1, 1])  # Slice the (1, 1) element from each 'layer'\n",
    "print(tensor_3d[0:2, :, 0])  # Slice the first two 'layers' and extract the first column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Modification of elements\n",
    "* The tensorflow does not support item assignment occurs when you attempt to directly modify an individual element of a TensorFlow tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Mutability and In-Place Modification\n",
    "* One of the main features of tf.Variable is its mutability. \n",
    "* You can modify the value of a variable using the `assign()`, `assign_add()`, or `assign_sub()` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After assign(new_value): 10.0\n",
      "After assign_add(increment_by): 12.0\n",
      "After assign_sub(decrement_by): 9.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create a TensorFlow variable initialized with a scalar value\n",
    "var = tf.Variable(5.0)\n",
    "\n",
    "# Example: Using assign() to set a new value\n",
    "new_value = 10.0\n",
    "var.assign(new_value)\n",
    "\n",
    "print(\"After assign(new_value):\", var.numpy())  # Output: 10.0\n",
    "\n",
    "# Example: Using assign_add() to increment the variable\n",
    "increment_by = 2.0\n",
    "var.assign_add(increment_by)\n",
    "\n",
    "print(\"After assign_add(increment_by):\", var.numpy())  # Output: 12.0\n",
    "\n",
    "# Example: Using assign_sub() to decrement the variable\n",
    "decrement_by = 3.0\n",
    "var.assign_sub(decrement_by)\n",
    "\n",
    "print(\"After assign_sub(decrement_by):\", var.numpy())  # Output: 9.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Modifying Individual Elements\n",
    "* You can modify individual elements (or slices) of a tf.Variable using the `assign()` method on specific indices or slices.\n",
    "* Direct item assignment `(var[0] = value)` does `not work` on tf.Variable objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 5 3 4]\n",
      "[1 3 3 4]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create a tf.Variable\n",
    "var = tf.Variable([1, 2, 3, 4])\n",
    "\n",
    "# Modify individual elements using assign() method\n",
    "var[1].assign(5)  # Modify the second element to 5\n",
    "print(var.numpy())  # Output: [1, 5, 3, 4]\n",
    "\n",
    "# Modify range of elements using assign() method\n",
    "var[1:3].assign(3)  # Modify the second element to 5\n",
    "print(var.numpy())  # Output: [1, 5, 3, 4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Advanced Modification with `scatter_nd_update()`\n",
    "* TensorFlow provides advanced method like `scatter_nd_update()` to modify specific elements or slices of a variable based on indices.\n",
    "* These methods are useful for updating variable values in a more complex and efficient manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After scatter_nd_update(indices_sparse, updates_sparse): [0. 5. 0. 7.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create a TensorFlow variable initialized with zeros\n",
    "var = tf.Variable([0.0, 0.0, 0.0, 0.0])\n",
    "\n",
    "# Define sparse indices and updates\n",
    "indices_sparse = tf.constant([[1], [3]])  # Define sparse indices as a 2D tensor\n",
    "updates_sparse = tf.constant([5.0, 7.0])  # Define corresponding sparse updates\n",
    "\n",
    "# Perform sparse scatter_nd_update\n",
    "updated_var = tf.tensor_scatter_nd_update(var, indices_sparse, updates_sparse)\n",
    "\n",
    "print(\"After scatter_nd_update(indices_sparse, updates_sparse):\", updated_var.numpy())\n",
    "# Output: [0.0, 5.0, 0.0, 7.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After scatter_nd_update(indices_sparse, updates_sparse):\n",
      "[[0. 5. 0.]\n",
      " [0. 0. 7.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create a TensorFlow variable initialized with zeros (2D tensor)\n",
    "var = tf.Variable([[0.0, 0.0, 0.0],\n",
    "                   [0.0, 0.0, 0.0],\n",
    "                   [0.0, 0.0, 0.0]])\n",
    "\n",
    "# Define sparse indices and updates for a 2D tensor\n",
    "indices_sparse = tf.constant([[0, 1],   # Update element at row 0, column 1\n",
    "                              [1, 2]])  # Update element at row 1, column 2\n",
    "\n",
    "updates_sparse = tf.constant([5.0, 7.0])  # Corresponding sparse update values\n",
    "\n",
    "# Perform sparse scatter_nd_update on the 2D tensor\n",
    "updated_var = tf.tensor_scatter_nd_update(var, indices_sparse, updates_sparse)\n",
    "\n",
    "print(\"After scatter_nd_update(indices_sparse, updates_sparse):\")\n",
    "print(updated_var.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After modifying the range of elements:\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 5. 7. 3.]\n",
      " [0. 1. 2. 4.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create a TensorFlow variable initialized with zeros (2D tensor: 3x4 matrix)\n",
    "var = tf.Variable([[0.0, 0.0, 0.0, 0.0],\n",
    "                   [0.0, 0.0, 0.0, 0.0],\n",
    "                   [0.0, 0.0, 0.0, 0.0]])\n",
    "\n",
    "# Define the range of row and column indices to update (slicing)\n",
    "start_row = 1\n",
    "end_row = 3\n",
    "start_col = 1\n",
    "end_col = 4\n",
    "\n",
    "# Generate new values for the specified range (2D tensor: corresponding submatrix)\n",
    "new_values = tf.constant([[5.0, 7.0, 3.0],\n",
    "                          [1.0, 2.0, 4.0]])\n",
    "\n",
    "# Calculate the dimensions of the new values tensor\n",
    "num_rows, num_cols = new_values.shape\n",
    "\n",
    "# Generate indices for the range to update using meshgrid and stack\n",
    "rows, cols = tf.meshgrid(tf.range(start_row, end_row), tf.range(start_col, end_col), indexing='ij')\n",
    "indices_sparse = tf.stack([rows, cols], axis=-1)\n",
    "\n",
    "# Perform sparse scatter_nd_update to modify the specified submatrix range\n",
    "updated_var = tf.tensor_scatter_nd_update(var, indices_sparse, new_values)\n",
    "\n",
    "print(\"After modifying the range of elements:\")\n",
    "print(updated_var.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Array Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1 2 3 4]], shape=(1, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# .reshape():\n",
    "# .reshape() is used to change the shape of a tensor while keeping the same underlying data.\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Create a tensor\n",
    "x = tf.constant([[1, 2],\n",
    "                 [3, 4]])\n",
    "\n",
    "# Reshape the tensor to a new shape\n",
    "x_reshaped = tf.reshape(x, [1, 4])  # Reshape to shape (1, 4)\n",
    "print(x_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# tf.squeeze():\n",
    "# This function removes dimensions of size 1 from the shape of a tensor.\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Create a tensor with shape (1, 3, 1)\n",
    "x = tf.constant([[[1], [2], [3]]])\n",
    "\n",
    "# Squeeze the tensor to remove dimensions of size 1\n",
    "x_squeezed = tf.squeeze(x)\n",
    "print(x_squeezed)  # Output shape will be (3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2 1 2 1 2]\n",
      " [3 4 3 4 3 4]\n",
      " [1 2 1 2 1 2]\n",
      " [3 4 3 4 3 4]], shape=(4, 6), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# tile():\n",
    "# tf.tile() is used to construct a new tensor by tiling the input tensor.\n",
    "# It replicates the input tensor's data along specified dimensions.\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Create a tensor\n",
    "x = tf.constant([[1, 2],\n",
    "                 [3, 4]])\n",
    "\n",
    "# Tile the tensor along rows and columns\n",
    "x_tiled = tf.tile(x, [2, 3])  # Tile to (2, 3) replication\n",
    "print(x_tiled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Arithmetic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define a 2D tensor (3x3)\n",
    "tensor_a = tf.random.normal((3, 3), mean=0.0, stddev=1.0, dtype=tf.float32)\n",
    "tensor_b = tf.random.normal((3, 3), mean=0.0, stddev=1.0, dtype=tf.float32)\n",
    "\n",
    "# Addition: Element-wise addition of two tensors.\n",
    "result = tf.add(tensor_a, tensor_b)\n",
    "result = tensor_a.__add__(tensor_b)\n",
    "result = tensor_a + tensor_b\n",
    "# Subtraction: Element-wise subtraction of two tensors.\n",
    "result = tf.subtract(tensor_a, tensor_b)\n",
    "# Multiplication: Element-wise multiplication of two tensors.\n",
    "result = tf.multiply(tensor_a, tensor_b)\n",
    "# Division: Element-wise division of two tensors.\n",
    "result = tf.divide(tensor_a, tensor_b)\n",
    "# Exponentiation: Element-wise exponentiation of a tensor.\n",
    "exponent = 2\n",
    "result = tf.pow(tensor_a, exponent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Broadcasting Basics\n",
    "* Broadcasting is a technique used in TensorFlow to perform `element-wise operations` on tensors of different shapes by implicitly aligning their dimensions. The main concept is to extend (or \"broadcast\") smaller tensors to match the shape of larger tensors before applying element-wise operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  4  6]\n",
      " [ 8 10 12]]\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Broadcasting Scalars\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define a tensor with shape (2, 3)\n",
    "tensor_a = tf.constant([[1, 2, 3],\n",
    "                         [4, 5, 6]])\n",
    "\n",
    "# Define a scalar value\n",
    "scalar_b = tf.constant(2)\n",
    "\n",
    "# Element-wise multiplication using broadcasting\n",
    "result = tensor_a * scalar_b\n",
    "\n",
    "# Display the result\n",
    "print(result.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11 22 33]\n",
      " [14 25 36]]\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Broadcasting Vectors\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define a matrix with shape (2, 3)\n",
    "matrix_a = tf.constant([[1, 2, 3],\n",
    "                        [4, 5, 6]])\n",
    "\n",
    "# Define a vector with shape (3,)\n",
    "vector_b = tf.constant([10, 20, 30])\n",
    "\n",
    "# Element-wise addition using broadcasting\n",
    "result = matrix_a + vector_b\n",
    "\n",
    "# Display the result\n",
    "print(result.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 10  20  30]\n",
      " [ 80 100 120]]\n"
     ]
    }
   ],
   "source": [
    "# Example 3: Broadcasting Along Different Axes\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define a matrix with shape (2, 3)\n",
    "matrix_a = tf.constant([[1, 2, 3],\n",
    "                        [4, 5, 6]])\n",
    "\n",
    "# Define a vector with shape (2,)\n",
    "vector_c = tf.constant([10, 20])\n",
    "\n",
    "# Element-wise multiplication using broadcasting along different axes\n",
    "result = matrix_a * vector_c[:, tf.newaxis]\n",
    "\n",
    "# Display the result\n",
    "print(result.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Reduction operations\n",
    "* Reduction operations in TensorFlow are used to compute aggregate values (e.g., sum, mean, maximum, minimum) over specific dimensions of a tensor, resulting in a tensor with reduced dimensions or a scalar value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum along axis 0: [5 7 9]\n",
      "Sum along axis 1: [ 6 15]\n"
     ]
    }
   ],
   "source": [
    "# 1. tf.reduce_sum\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define a tensor\n",
    "tensor = tf.constant([[1, 2, 3],\n",
    "                       [4, 5, 6]])\n",
    "\n",
    "# Compute sum along axis 0 (sum of each column)\n",
    "sum_along_axis0 = tf.reduce_sum(tensor, axis=0)\n",
    "\n",
    "# Compute sum along axis 1 (sum of each row)\n",
    "sum_along_axis1 = tf.reduce_sum(tensor, axis=1)\n",
    "\n",
    "print(\"Sum along axis 0:\", sum_along_axis0.numpy())  # Output: [5 7 9]\n",
    "print(\"Sum along axis 1:\", sum_along_axis1.numpy())  # Output: [ 6 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean along axis 0: [2 3 4]\n",
      "Mean along axis 1: [2 5]\n"
     ]
    }
   ],
   "source": [
    "# 2. tf.reduce_mean\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define a tensor\n",
    "tensor = tf.constant([[1, 2, 3],\n",
    "                       [4, 5, 6]])\n",
    "\n",
    "# Compute mean along axis 0 (mean of each column)\n",
    "mean_along_axis0 = tf.reduce_mean(tensor, axis=0)\n",
    "\n",
    "# Compute mean along axis 1 (mean of each row)\n",
    "mean_along_axis1 = tf.reduce_mean(tensor, axis=1)\n",
    "\n",
    "print(\"Mean along axis 0:\", mean_along_axis0.numpy())  # Output: [2.5 3.5 4.5]\n",
    "print(\"Mean along axis 1:\", mean_along_axis1.numpy())  # Output: [2. 5.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum along axis 0: [4 5 6]\n",
      "Minimum along axis 1: [1 4]\n"
     ]
    }
   ],
   "source": [
    "# 3. tf.reduce_max and tf.reduce_min\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define a tensor\n",
    "tensor = tf.constant([[1, 2, 3],\n",
    "                       [4, 5, 6]])\n",
    "\n",
    "# Compute maximum along axis 0 (maximum of each column)\n",
    "max_along_axis0 = tf.reduce_max(tensor, axis=0)\n",
    "\n",
    "# Compute minimum along axis 1 (minimum of each row)\n",
    "min_along_axis1 = tf.reduce_min(tensor, axis=1)\n",
    "\n",
    "print(\"Maximum along axis 0:\", max_along_axis0.numpy())  # Output: [4 5 6]\n",
    "print(\"Minimum along axis 1:\", min_along_axis1.numpy())  # Output: [1 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation (all elements): 1.7078252\n",
      "Standard Deviation along axis 0 (column-wise): [1.5 1.5 1.5]\n",
      "Standard Deviation along axis 1 (row-wise): [0.8164966 0.8164966]\n"
     ]
    }
   ],
   "source": [
    "# 4. tf.math.reduce_std\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define a tensor\n",
    "tensor = tf.constant([[1.0, 2.0, 3.0],\n",
    "                       [4.0, 5.0, 6.0]])\n",
    "\n",
    "# Compute the standard deviation across all elements\n",
    "std_all = tf.math.reduce_std(tensor)\n",
    "\n",
    "# Compute the standard deviation along axis 0 (column-wise)\n",
    "std_axis0 = tf.math.reduce_std(tensor, axis=0)\n",
    "\n",
    "# Compute the standard deviation along axis 1 (row-wise)\n",
    "std_axis1 = tf.math.reduce_std(tensor, axis=1)\n",
    "\n",
    "print(\"Standard Deviation (all elements):\", std_all.numpy())\n",
    "print(\"Standard Deviation along axis 0 (column-wise):\", std_axis0.numpy())\n",
    "print(\"Standard Deviation along axis 1 (row-wise):\", std_axis1.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Basic Mathematical Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define a 2D tensor (3x3)\n",
    "tensor = tf.random.normal((3, 3), mean=0.0, stddev=1.0, dtype=tf.float32)\n",
    "\n",
    "# Square Root: Element-wise square root of a tensor.\n",
    "result = tf.sqrt(tensor)\n",
    "# Absolute Value: Element-wise absolute value of a tensor.\n",
    "result = tf.abs(tensor)\n",
    "# Negative: Element-wise negation of a tensor.\n",
    "result = tf.negative(tensor)\n",
    "# Sine, Cosine, Tangent: Element-wise trigonometric functions.\n",
    "result_sin = tf.sin(tensor)\n",
    "result_cos = tf.cos(tensor)\n",
    "result_tan = tf.tan(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Matrix Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiplication of the tensors\n",
    "import tensorflow as tf\n",
    "\n",
    "# Matrix multiplication\n",
    "mat1 = tf.constant([[1, 2], [3, 4]])\n",
    "mat2 = tf.constant([[5, 6], [7, 8]])\n",
    "mat_mult = tf.matmul(mat1, mat2)\n",
    "\n",
    "\n",
    "# Perform matrix multiplication using the @ operator\n",
    "mat_mult = mat1 @ mat2  # This is equivalent to tf.matmul(mat1, mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [4 5 6]], shape=(2, 3), dtype=int32)\n",
      "Transposed tensor:\n",
      "tf.Tensor(\n",
      "[[1 4]\n",
      " [2 5]\n",
      " [3 6]], shape=(3, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Transpose of a tensor\n",
    "import tensorflow as tf\n",
    "\n",
    "# Create a tensor with shape (2, 3)\n",
    "x = tf.constant([[1, 2, 3],\n",
    "                 [4, 5, 6]])\n",
    "\n",
    "# Transpose the tensor\n",
    "x_transposed = tf.transpose(x)  # By default, this swaps the first and second dimensions\n",
    "\n",
    "print(\"Original tensor:\")\n",
    "print(x)\n",
    "print(\"Transposed tensor:\")\n",
    "print(x_transposed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original matrix A:\n",
      "tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]], shape=(2, 2), dtype=float32)\n",
      "Inverse of matrix A:\n",
      "tf.Tensor(\n",
      "[[-2.0000002   1.0000001 ]\n",
      " [ 1.5000001  -0.50000006]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Inverse of a tensor\n",
    "import tensorflow as tf\n",
    "\n",
    "# Create a square matrix (2x2) as a TensorFlow constant\n",
    "A = tf.constant([[1.0, 2.0],\n",
    "                 [3.0, 4.0]])\n",
    "\n",
    "# Compute the inverse of the matrix A\n",
    "A_inverse = tf.linalg.inv(A)\n",
    "\n",
    "# Print the original matrix and its inverse\n",
    "print(\"Original matrix A:\")\n",
    "print(A)\n",
    "\n",
    "print(\"Inverse of matrix A:\")\n",
    "print(A_inverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Comparison Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define a 2D tensor (3x3)\n",
    "tensor_a = tf.random.normal((3, 3), mean=0.0, stddev=1.0, dtype=tf.float32)\n",
    "tensor_b = tf.random.normal((3, 3), mean=0.0, stddev=1.0, dtype=tf.float32)\n",
    "\n",
    "# Create condition_a and condition_b boolean tensors\n",
    "condition_a = tf.constant([True, False, True])   # Example boolean tensor 1\n",
    "condition_b = tf.constant([False, True, True])   # Example boolean tensor 2\n",
    "\n",
    "# Equal: Element-wise equality comparison of two tensors.\n",
    "result = tf.equal(tensor_a, tensor_b)\n",
    "# Not Equal: Element-wise inequality comparison of two tensors.\n",
    "result = tf.not_equal(tensor_a, tensor_b)\n",
    "# Greater Than, Less Than: Element-wise comparison of two tensors.\n",
    "result_gt = tf.greater(tensor_a, tensor_b)\n",
    "result_lt = tf.less(tensor_a, tensor_b)\n",
    "# Logical AND, OR: Element-wise logical operations.\n",
    "result_and = tf.logical_and(condition_a, condition_b)\n",
    "result_or = tf.logical_or(condition_a, condition_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Clipping and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define a tensor with values\n",
    "tensor = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "\n",
    "# Clip the tensor values to be between 2.0 and 4.0\n",
    "clipped_tensor = tf.clip_by_value(tensor, clip_value_min=2.0, clip_value_max=4.0)\n",
    "\n",
    "# Perform L2 normalization along axis 1 (normalize each row)\n",
    "normalized_x = tf.nn.l2_normalize(tensor, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define a tensor with values\n",
    "tensor = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "\n",
    "# Is NaN, Is Finite: Element-wise checks for NaN (Not a Number) and finite values.\n",
    "result_isnan = tf.math.is_nan(tensor)\n",
    "result_isfinite = tf.math.is_finite(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Applying TensorFlow Operations to NumPy Arrays\n",
    "* You can convert NumPy arrays to TensorFlow tensors using `tf.convert_to_tensor()` and then apply TensorFlow operations to these tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result (TensorFlow tensor):\n",
      "tf.Tensor(\n",
      "[[ 1.  4.]\n",
      " [ 9. 16.]], shape=(2, 2), dtype=float64)\n",
      "Result (NumPy array):\n",
      "[[ 1.  4.]\n",
      " [ 9. 16.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Create a NumPy array\n",
    "numpy_array = np.array([[1.0, 2.0],\n",
    "                         [3.0, 4.0]])\n",
    "\n",
    "# Convert NumPy array to a TensorFlow tensor\n",
    "tensor = tf.convert_to_tensor(numpy_array)\n",
    "\n",
    "# Apply TensorFlow operations to the tensor\n",
    "result = tf.square(tensor)  # Square each element\n",
    "\n",
    "# Convert the result back to a NumPy array (if needed)\n",
    "result_numpy = result.numpy()\n",
    "\n",
    "print(\"Result (TensorFlow tensor):\")\n",
    "print(result)\n",
    "\n",
    "print(\"Result (NumPy array):\")\n",
    "print(result_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You can apply TensorFlow operations on a NumPy array without converting it to a TensorFlow tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result (NumPy array after TensorFlow operation):\n",
      "tf.Tensor(\n",
      "[[ 1.  4.]\n",
      " [ 9. 16.]], shape=(2, 2), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Create a NumPy array\n",
    "numpy_array = np.array([[1.0, 2.0],\n",
    "                         [3.0, 4.0]])\n",
    "\n",
    "# Apply TensorFlow operations directly on the NumPy array\n",
    "result_numpy = tf.square(numpy_array)  # Square each element using NumPy operation\n",
    "\n",
    "print(\"Result (NumPy array after TensorFlow operation):\")\n",
    "print(result_numpy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Applying NumPy Operations to TensorFlow Tensors\n",
    "* Similarly, you can convert TensorFlow tensors to NumPy arrays using .numpy() and apply NumPy operations to these arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result (NumPy array):\n",
      "[[1.        1.4142135]\n",
      " [1.7320508 2.       ]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Create a TensorFlow tensor\n",
    "tensor = tf.constant([[1.0, 2.0],\n",
    "                      [3.0, 4.0]])\n",
    "\n",
    "# Convert TensorFlow tensor to a NumPy array\n",
    "numpy_array = tensor.numpy()\n",
    "\n",
    "# Apply NumPy operations to the NumPy array\n",
    "result_numpy = np.sqrt(numpy_array)  # Compute element-wise square root\n",
    "\n",
    "print(\"Result (NumPy array):\")\n",
    "print(result_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To apply NumPy operations directly on TensorFlow tensors without converting them explicitly, you can utilize TensorFlow's ability to seamlessly interoperate with NumPy arrays within eager execution mode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result (NumPy array after applying NumPy operation on TensorFlow tensor):\n",
      "[[ 1.  4.]\n",
      " [ 9. 16.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Create a TensorFlow tensor\n",
    "tensor = tf.constant([[1.0, 2.0],\n",
    "                      [3.0, 4.0]])\n",
    "\n",
    "# Apply NumPy operations directly on the TensorFlow tensor\n",
    "result_numpy = np.square(tensor.numpy())  # Square each element using NumPy operation on tensor's numpy array\n",
    "\n",
    "print(\"Result (NumPy array after applying NumPy operation on TensorFlow tensor):\")\n",
    "print(result_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Operations Between Tensors of Different Types\n",
    "\n",
    "* When you attempt to perform operations (like addition, multiplication, etc.) between tensors of different data types, TensorFlow will `raise an exception` indicating the type incompatibility.\n",
    "* If you need to perform operations between tensors of different types, you can `explicitly convert tensors` to compatible types using `tf.cast()`:\n",
    "* It's important to maintain data type consistency in your TensorFlow computations to ensure efficient execution and avoid unnecessary type conversions. When building TensorFlow models, specifying data types explicitly can help in optimizing performance and avoiding unexpected behaviors due to type mismatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute AddV2 as input #1(zero-based) was expected to be a int32 tensor but is a float tensor [Op:AddV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m tensor_float \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant(\u001b[38;5;241m3.0\u001b[39m)  \u001b[38;5;66;03m# Float tensor\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Attempt to add tensors of different types\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtensor_int\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtensor_float\u001b[49m  \u001b[38;5;66;03m# This will raise a TypeError\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dodge\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\dodge\\.conda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7209\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7208\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 7209\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: cannot compute AddV2 as input #1(zero-based) was expected to be a int32 tensor but is a float tensor [Op:AddV2]"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create tensors of different types\n",
    "tensor_int = tf.constant(5)  # Integer tensor\n",
    "tensor_float = tf.constant(3.0)  # Float tensor\n",
    "\n",
    "# Attempt to add tensors of different types\n",
    "result = tensor_int + tensor_float  # This will raise a TypeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicit Type Conversion\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Create tensors of different types\n",
    "tensor_int = tf.constant(5)  # Integer tensor\n",
    "tensor_float = tf.constant(3.0)  # Float tensor\n",
    "\n",
    "# Convert integer tensor to float\n",
    "tensor_int_float = tf.cast(tensor_int, tf.float32)\n",
    "\n",
    "# Perform addition after type conversion\n",
    "result = tensor_int_float + tensor_float  # This will work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. SparseTensor in TensorFlow\n",
    "\n",
    "* Sparse tensors in TensorFlow are a special type of tensor that efficiently represents and manipulates tensors containing mostly zero values. \n",
    "* This is particularly useful for handling sparse data structures where most elements are zero, such as sparse matrices or high-dimensional data with sparse representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor:\n",
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 1]\n",
      " [1 2]\n",
      " [2 0]], shape=(3, 2), dtype=int64), values=tf.Tensor([3. 4. 5.], shape=(3,), dtype=float32), dense_shape=tf.Tensor([3 3], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# 1. Creating a SparseTensor\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the non-zero elements and their indices\n",
    "indices = tf.constant([[0, 1], [1, 2], [2, 0]])  # Example indices with dtype int32\n",
    "values = tf.constant([3.0, 4.0, 5.0])             # Corresponding non-zero values\n",
    "dense_shape = tf.constant([3, 3], dtype=tf.int64)  # Shape of the dense tensor (3x3) with dtype int64\n",
    "\n",
    "# Convert indices to dtype int64 (if needed, though it's already int64 in this case)\n",
    "indices = tf.cast(indices, dtype=tf.int64)\n",
    "\n",
    "# Create the SparseTensor\n",
    "sparse_tensor = tf.sparse.SparseTensor(indices=indices, values=values, dense_shape=dense_shape)\n",
    "\n",
    "print(\"SparseTensor:\")\n",
    "print(sparse_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense Tensor:\n",
      "tf.Tensor(\n",
      "[[0. 3. 0.]\n",
      " [0. 0. 4.]\n",
      " [5. 0. 0.]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 2. Converting SparseTensor to Dense Tensor\n",
    "\n",
    "dense_tensor = tf.sparse.to_dense(sparse_tensor)\n",
    "print(\"Dense Tensor:\")\n",
    "print(dense_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value at index (1, 2): 4.0\n"
     ]
    }
   ],
   "source": [
    "# 3. Accessing Elements of SparseTensor\n",
    "\n",
    "# Define the example sparse tensor\n",
    "indices = tf.constant([[0, 1], [1, 2], [2, 0]], dtype=tf.int64)\n",
    "values = tf.constant([3.0, 4.0, 5.0])\n",
    "dense_shape = tf.constant([3, 3], dtype=tf.int64)\n",
    "sparse_tensor = tf.sparse.SparseTensor(indices=indices, values=values, dense_shape=dense_shape)\n",
    "\n",
    "# Accessing a specific element at row=1, column=2\n",
    "row_index = 1\n",
    "col_index = 2\n",
    "\n",
    "# Convert sparse tensor to dense tensor and access the element\n",
    "dense_tensor = tf.sparse.to_dense(sparse_tensor)\n",
    "element_value = dense_tensor[row_index, col_index]\n",
    "\n",
    "print(\"Value at index ({}, {}):\".format(row_index, col_index), element_value.numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled SparseTensor:\n",
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 1]\n",
      " [1 2]\n",
      " [2 0]], shape=(3, 2), dtype=int64), values=tf.Tensor([ 6.  8. 10.], shape=(3,), dtype=float32), dense_shape=tf.Tensor([3 3], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# 4. Performing Element-wise Operations\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the example sparse tensor\n",
    "indices = tf.constant([[0, 1], [1, 2], [2, 0]], dtype=tf.int64)\n",
    "values = tf.constant([3.0, 4.0, 5.0])\n",
    "dense_shape = tf.constant([3, 3], dtype=tf.int64)\n",
    "sparse_tensor = tf.sparse.SparseTensor(indices=indices, values=values, dense_shape=dense_shape)\n",
    "\n",
    "# Define the scalar value for multiplication\n",
    "scalar = 2.0\n",
    "\n",
    "# Perform element-wise multiplication of SparseTensor values by the scalar\n",
    "scaled_values = sparse_tensor.values * scalar\n",
    "\n",
    "# Create a new SparseTensor with the scaled values\n",
    "scaled_sparse_tensor = tf.sparse.SparseTensor(indices=sparse_tensor.indices,\n",
    "                                              values=scaled_values,\n",
    "                                              dense_shape=sparse_tensor.dense_shape)\n",
    "\n",
    "print(\"Scaled SparseTensor:\")\n",
    "print(scaled_sparse_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated SparseTensor:\n",
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 1]\n",
      " [1 2]\n",
      " [2 0]\n",
      " [3 1]\n",
      " [4 2]\n",
      " [5 0]], shape=(6, 2), dtype=int64), values=tf.Tensor([ 3.  4.  5.  6.  8. 10.], shape=(6,), dtype=float32), dense_shape=tf.Tensor([6 3], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# 5. Combining SparseTensors\n",
    "\n",
    "# Concatenate SparseTensors along a specified axis\n",
    "concatenated_sparse_tensor = tf.sparse.concat(axis=0, sp_inputs=[sparse_tensor, scaled_sparse_tensor])\n",
    "print(\"Concatenated SparseTensor:\")\n",
    "print(concatenated_sparse_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of SparseTensor * DenseMatrix:\n",
      "tf.Tensor(\n",
      "[[0. 3. 0.]\n",
      " [0. 0. 4.]\n",
      " [5. 0. 0.]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 6. Applying Operations to SparseTensors\n",
    "\n",
    "# Example: Use SparseTensor in a TensorFlow operation (e.g., matrix multiplication)\n",
    "dense_matrix = tf.constant([[1.0, 0.0, 0.0],\n",
    "                            [0.0, 1.0, 0.0],\n",
    "                            [0.0, 0.0, 1.0]])\n",
    "\n",
    "result_sparse_tensor = tf.sparse.sparse_dense_matmul(sparse_tensor, dense_matrix)\n",
    "print(\"Result of SparseTensor * DenseMatrix:\")\n",
    "print(result_sparse_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. String tensors in TensorFlow \n",
    "* These tensors are used to handle and manipulate string data within TensorFlow computational graphs, which can be useful for tasks like natural language processing (NLP), text generation, and preprocessing textual "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String Tensor:\n",
      "tf.Tensor(b'Hello, TensorFlow!', shape=(), dtype=string)\n",
      "String Tensor:\n",
      "tf.Tensor([b'apple' b'banana' b'orange'], shape=(3,), dtype=string)\n",
      "String Lengths:\n",
      "tf.Tensor([5 6 6], shape=(3,), dtype=int32)\n",
      "Concatenated String:\n",
      "tf.Tensor(b'Hello, TensorFlow', shape=(), dtype=string)\n",
      "String Element:\n",
      "tf.Tensor(b'apple', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# Creating String Tensors\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Create a string tensor using tf.constant()\n",
    "string_tensor = tf.constant(\"Hello, TensorFlow!\")\n",
    "\n",
    "print(\"String Tensor:\")\n",
    "print(string_tensor)\n",
    "\n",
    "# Create a string tensor from a list of strings\n",
    "string_list = [\"apple\", \"banana\", \"orange\"]\n",
    "string_tensor = tf.constant(string_list)\n",
    "\n",
    "print(\"String Tensor:\")\n",
    "print(string_tensor)\n",
    "\n",
    "# Compute the length of each string in the tensor\n",
    "string_lengths = tf.strings.length(string_tensor)\n",
    "\n",
    "print(\"String Lengths:\")\n",
    "print(string_lengths)\n",
    "\n",
    "# Concatenate two string tensors\n",
    "string_tensor1 = tf.constant(\"Hello\")\n",
    "string_tensor2 = tf.constant(\"TensorFlow\")\n",
    "concatenated_string = tf.strings.join([string_tensor1, string_tensor2], separator=\", \")\n",
    "\n",
    "print(\"Concatenated String:\")\n",
    "print(concatenated_string)\n",
    "\n",
    "# Accessing individual string elements\n",
    "string_element = string_tensor[0]  # Access the first element of the string tensor\n",
    "\n",
    "print(\"String Element:\")\n",
    "print(string_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Customizing Models and Training Algorithms`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Huber loss function\n",
    "* The Huber loss function combines the benefits of the mean squared error (MSE) for small errors and the mean absolute error (MAE) for large errors, resulting in a robust loss function that is less sensitive to outliers compared to pure MSE.\n",
    "* **Robustness to Outliers:** The Huber loss function is designed to be more robust to outliers compared to the traditional squared loss (mean squared error, MSE). It achieves this by treating errors differently based on their magnitude:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_fn(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Huber loss function implementation.\n",
    "    \"\"\"\n",
    "    # Calculate the error (difference between true and predicted values)\n",
    "    error = y_true - y_pred\n",
    "    # Determine which errors are considered \"small\" (absolute error < 1)\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    # Compute the squared loss for small errors (squared error / 2)\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    # Compute the linear loss for large errors (absolute error - 0.5)\n",
    "    linear_loss = tf.abs(error) - 0.5\n",
    "    # Use a conditional statement to select between squared_loss and linear_loss\n",
    "    # based on whether the error is considered \"small\" or \"large\"\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Visualizing the Huber loss function\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(4, 2))\n",
    "z = np.linspace(-4, 4, 200)\n",
    "plt.plot(z, huber_fn(0, z), \"b-\", linewidth=2, label=\"huber($z$)\")\n",
    "plt.plot(z, z**2 / 2, \"b:\", linewidth=1, label=r\"$\\frac{1}{2}z^2$\")\n",
    "plt.plot([-1, -1], [0, huber_fn(0., -1.)], \"r--\")\n",
    "plt.plot([1, 1], [0, huber_fn(0., 1.)], \"r--\")\n",
    "plt.gca().axhline(y=0, color='k')\n",
    "plt.gca().axvline(x=0, color='k')\n",
    "plt.axis([-4, 4, 0, 4])\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"$z$\")\n",
    "plt.legend(fontsize=14)\n",
    "plt.title(\"Huber loss\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6947 - mae: 1.0558 - val_loss: 0.2328 - val_mae: 0.5292\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2087 - mae: 0.5027 - val_loss: 0.2013 - val_mae: 0.4841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21b837056c0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Neural Network with Huber Loss using TensorFlow/Keras\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the California housing dataset\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "# Standardize the input features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the Huber loss function for regression\n",
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "\n",
    "# Determine the input shape for the neural network\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# Build a sequential neural network model using Keras\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "# Compile the model with Huber loss function and Nadam optimizer\n",
    "model.compile(loss=huber_fn, optimizer=\"nadam\", metrics=[\"mae\"])\n",
    "\n",
    "# Train the model on the scaled training data with validation data\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving/Loading Models with Custom Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Model with the Custom Loss Function\n",
    "model.save(\"my_model_with_a_custom_loss.h5\")\n",
    "\n",
    "# Load the Model with the Custom Loss Function\n",
    "\n",
    "# Create a dictionary where you map the names of your functions or objects to\n",
    "# the actual functions or objects themselves. This dictionary will be used to \n",
    "# load and access these custom components later on. \n",
    "custom_objects={\"huber_fn\": huber_fn}\n",
    "\n",
    "model = keras.models.load_model(\"my_model_with_a_custom_loss.h5\",\n",
    "                                custom_objects)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
